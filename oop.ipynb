{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import ollama\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT: str = \"You are a helpful assistant. Answer extremely concisely.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Message(BaseModel):\n",
    "    \"\"\"A single message in the conversation.\"\"\"\n",
    "\n",
    "    role: Literal[\"system\", \"user\", \"assistant\"]\n",
    "    content: str\n",
    "\n",
    "\n",
    "class Conversation(BaseModel):\n",
    "    \"\"\"Manages a conversation with message history.\"\"\"\n",
    "\n",
    "    history: list[Message] = Field(\n",
    "        default_factory=lambda: [Message(role=\"system\", content=SYSTEM_PROMPT)]\n",
    "    )\n",
    "    model: str = \"llama3.2\"\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        \"\"\"Ask a question and get a response, maintaining conversation history.\"\"\"\n",
    "        self.history.append(Message(role=\"user\", content=question))\n",
    "\n",
    "        messages = [msg.model_dump() for msg in self.history]\n",
    "        response = ollama.chat(model=self.model, messages=messages)\n",
    "        answer = response[\"message\"][\"content\"]\n",
    "\n",
    "        self.history.append(Message(role=\"assistant\", content=answer))\n",
    "        return answer\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Reset the conversation history.\"\"\"\n",
    "        self.history = [Message(role=\"system\", content=SYSTEM_PROMPT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new conversation\n",
    "logger.info(\"Creating a new conversation\")\n",
    "conversation = Conversation()\n",
    "\n",
    "# Ask initial question\n",
    "question = \"What is Iceland?\"\n",
    "answer = conversation.ask(question)\n",
    "logger.info(f\"Question: {question}\")\n",
    "logger.success(f\"Answer: {answer}\")\n",
    "\n",
    "# Ask a follow-up question\n",
    "followup = \"What is its population?\"\n",
    "answer = conversation.ask(followup)\n",
    "logger.info(f\"Follow-up: {followup}\")\n",
    "logger.success(f\"Answer: {answer}\")\n",
    "\n",
    "# To start fresh, reset the conversation:\n",
    "conversation.reset()\n",
    "# Or create a new instance:\n",
    "# conversation = Conversation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
